[2024-05-04T11:18:23.297+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:18:23.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:18:23.303+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:18:23.303+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:18:23.321+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:18:23.318+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 62, in <module>
    upload_file_geolocation = GCSToGCSOperator(
                              ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:18:23.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:18:23.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-05-04T11:18:53.628+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:18:53.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:18:53.629+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:18:53.629+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:18:53.657+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:18:53.636+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 62, in <module>
    upload_file_geolocation = GCSToGCSOperator(
                              ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:18:53.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:18:53.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.057 seconds
[2024-05-04T11:19:24.406+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:19:24.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:19:24.408+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:19:24.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:19:24.415+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:19:24.414+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 62, in <module>
    upload_file_geolocation = GCSToGCSOperator(
                              ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:19:24.416+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:19:24.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.036 seconds
[2024-05-04T11:19:55.150+0000] {processor.py:161} INFO - Started process (PID=959) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:19:55.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:19:55.153+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:19:55.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:19:55.162+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:19:55.161+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 62, in <module>
    upload_file_geolocation = GCSToGCSOperator(
                              ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:19:55.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:19:55.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.037 seconds
[2024-05-04T11:20:25.820+0000] {processor.py:161} INFO - Started process (PID=1225) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:20:25.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:20:25.822+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:20:25.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:20:25.831+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:20:25.829+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 62, in <module>
    upload_file_geolocation = GCSToGCSOperator(
                              ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:20:25.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:20:25.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.041 seconds
[2024-05-04T11:20:35.023+0000] {processor.py:161} INFO - Started process (PID=1346) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:20:35.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:20:35.035+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:20:35.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:20:35.099+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:20:35.096+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 234, in <module>
    start >> get_files >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
             ^^^^^^^^^
NameError: name 'get_files' is not defined. Did you mean: '_get_files'?
[2024-05-04T11:20:35.101+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:20:35.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.151 seconds
[2024-05-04T11:21:05.414+0000] {processor.py:161} INFO - Started process (PID=1612) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:21:05.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:21:05.416+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:05.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:21:05.436+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:05.434+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 234, in <module>
    start >> get_files >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
             ^^^^^^^^^
NameError: name 'get_files' is not defined. Did you mean: '_get_files'?
[2024-05-04T11:21:05.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:21:05.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.054 seconds
[2024-05-04T11:21:06.829+0000] {processor.py:161} INFO - Started process (PID=1635) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:21:06.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:21:06.830+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:06.830+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:21:06.848+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:21:06.983+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:06.982+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:21:07.025+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:07.025+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-03 00:00:00+00:00, run_after=2024-05-04 00:00:00+00:00
[2024-05-04T11:21:07.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.247 seconds
[2024-05-04T11:21:18.431+0000] {processor.py:161} INFO - Started process (PID=1789) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:21:18.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:21:18.438+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:18.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:21:18.538+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:21:18.597+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:18.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:21:18.931+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:18.931+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:21:19.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.653 seconds
[2024-05-04T11:21:31.722+0000] {processor.py:161} INFO - Started process (PID=1849) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:21:31.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:21:31.726+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:31.725+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:21:31.825+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:31.740+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 63
    task_id="upload_file_customers_to_capstone",
IndentationError: unexpected indent
[2024-05-04T11:21:31.825+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:21:31.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.250 seconds
[2024-05-04T11:21:42.883+0000] {processor.py:161} INFO - Started process (PID=2011) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:21:42.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:21:42.885+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:42.885+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:21:42.889+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:42.888+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 63
    task_id="upload_file_customers_to_capstone",
IndentationError: unexpected indent
[2024-05-04T11:21:42.890+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:21:42.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.039 seconds
[2024-05-04T11:21:44.140+0000] {processor.py:161} INFO - Started process (PID=2031) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:21:44.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:21:44.142+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:44.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:21:44.146+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:44.145+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 63
    task_id="upload_file_customers_to_capstone",
IndentationError: unexpected indent
[2024-05-04T11:21:44.147+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:21:44.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.040 seconds
[2024-05-04T11:21:48.808+0000] {processor.py:161} INFO - Started process (PID=2066) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:21:48.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:21:48.810+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:48.810+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:21:48.854+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:21:48.824+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 62, in <module>
    upload_file_geolocation = GCSToGCSOperator(
                              ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_customers_to_capstone' has already been added to the DAG
[2024-05-04T11:21:48.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:21:48.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.082 seconds
[2024-05-04T11:22:02.653+0000] {processor.py:161} INFO - Started process (PID=2135) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:02.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:02.654+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:02.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:02.679+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:02.666+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 62, in <module>
    upload_file_geolocation = GCSToGCSOperator(
                              ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_customers_to_capstone' has already been added to the DAG
[2024-05-04T11:22:02.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:02.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-05-04T11:22:13.350+0000] {processor.py:161} INFO - Started process (PID=2307) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:13.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:13.352+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:13.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:13.366+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:13.464+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:13.463+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:13.480+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:13.480+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:13.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.163 seconds
[2024-05-04T11:22:30.052+0000] {processor.py:161} INFO - Started process (PID=2363) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:30.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:30.053+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:30.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:30.070+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:30.079+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:30.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:30.097+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:30.097+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:30.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.072 seconds
[2024-05-04T11:22:32.677+0000] {processor.py:161} INFO - Started process (PID=2398) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:32.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:32.683+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:32.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:32.715+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:32.756+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:32.756+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:32.814+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:32.814+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:32.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-05-04T11:22:34.033+0000] {processor.py:161} INFO - Started process (PID=2436) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:34.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:34.035+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:34.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:34.055+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:34.074+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:34.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:34.100+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:34.099+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:34.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.099 seconds
[2024-05-04T11:22:36.628+0000] {processor.py:161} INFO - Started process (PID=2486) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:36.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:36.631+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:36.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:36.651+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:36.674+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:36.674+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:36.716+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:36.716+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:36.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.132 seconds
[2024-05-04T11:22:43.845+0000] {processor.py:161} INFO - Started process (PID=2578) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:43.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:43.847+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:43.847+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:43.867+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:44.029+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:44.028+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:44.077+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:44.077+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:44.108+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.269 seconds
[2024-05-04T11:22:48.549+0000] {processor.py:161} INFO - Started process (PID=2613) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:48.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:48.551+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:48.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:48.573+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:48.585+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:48.585+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:48.610+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:48.610+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:48.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.087 seconds
[2024-05-04T11:22:53.852+0000] {processor.py:161} INFO - Started process (PID=2648) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:53.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:53.853+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:53.853+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:53.869+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:53.879+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:53.878+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:22:53.897+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:53.897+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:22:53.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.072 seconds
[2024-05-04T11:22:55.889+0000] {processor.py:161} INFO - Started process (PID=2653) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:55.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:55.891+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:55.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:55.894+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:55.893+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 66
    task_id="upload_file_geolocation_to_capstone",
IndentationError: unexpected indent
[2024-05-04T11:22:55.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:55.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.031 seconds
[2024-05-04T11:22:58.969+0000] {processor.py:161} INFO - Started process (PID=2665) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:22:58.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:22:58.976+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:58.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:22:58.994+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:22:58.992+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 65, in <module>
    upload_file_items = GCSToGCSOperator(
                        ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_geolocation_to_capstone' has already been added to the DAG
[2024-05-04T11:22:59.002+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:22:59.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.117 seconds
[2024-05-04T11:23:00.196+0000] {processor.py:161} INFO - Started process (PID=2670) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:00.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:00.197+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:00.197+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:00.221+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:00.218+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 66, in <module>
    upload_file_items = GCSToGCSOperator(
                        ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_geolocation_to_capstone' has already been added to the DAG
[2024-05-04T11:23:00.226+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:00.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.101 seconds
[2024-05-04T11:23:07.396+0000] {processor.py:161} INFO - Started process (PID=2785) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:07.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:07.397+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:07.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:07.410+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:07.420+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:07.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:23:07.439+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:07.438+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:23:07.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.079 seconds
[2024-05-04T11:23:19.369+0000] {processor.py:161} INFO - Started process (PID=2905) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:19.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:19.371+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:19.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:19.389+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:19.510+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:19.510+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:23:19.693+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:19.693+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:23:19.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.351 seconds
[2024-05-04T11:23:22.101+0000] {processor.py:161} INFO - Started process (PID=2940) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:22.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:22.111+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:22.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:22.148+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:22.207+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:22.207+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:23:22.266+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:22.266+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:23:22.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.242 seconds
[2024-05-04T11:23:26.113+0000] {processor.py:161} INFO - Started process (PID=2945) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:26.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:26.115+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:26.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:26.137+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:26.148+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:26.148+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:23:26.168+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:26.167+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:23:26.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-05-04T11:23:30.148+0000] {processor.py:161} INFO - Started process (PID=2956) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:30.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:30.150+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:30.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:30.163+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:30.161+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 75, in <module>
    upload_file_payments = GCSToGCSOperator(
                           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:23:30.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:30.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.102 seconds
[2024-05-04T11:23:35.267+0000] {processor.py:161} INFO - Started process (PID=3029) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:35.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:35.268+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:35.268+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:35.282+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:35.279+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 75, in <module>
    upload_file_payments = GCSToGCSOperator(
                           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_items_to_capstone' has already been added to the DAG
[2024-05-04T11:23:35.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:35.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.054 seconds
[2024-05-04T11:23:40.498+0000] {processor.py:161} INFO - Started process (PID=3086) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:40.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:40.500+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:40.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:40.522+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:40.535+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:40.535+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:23:40.580+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:40.580+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:23:40.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.137 seconds
[2024-05-04T11:23:50.653+0000] {processor.py:161} INFO - Started process (PID=3226) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:50.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:50.654+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:50.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:50.671+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:50.931+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:50.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:23:50.952+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:50.952+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:23:50.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.329 seconds
[2024-05-04T11:23:58.710+0000] {processor.py:161} INFO - Started process (PID=3237) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:23:58.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:23:58.712+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:58.711+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:23:58.716+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:23:58.715+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 85
    task_id="upload_file_payments_to_capstone",
IndentationError: unexpected indent
[2024-05-04T11:23:58.716+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:23:58.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.055 seconds
[2024-05-04T11:24:00.724+0000] {processor.py:161} INFO - Started process (PID=3242) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:00.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:00.725+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:00.725+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:00.728+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:00.728+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 85
    task_id="upload_file_payments_to_capstone",
IndentationError: unexpected indent
[2024-05-04T11:24:00.729+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:00.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.030 seconds
[2024-05-04T11:24:01.738+0000] {processor.py:161} INFO - Started process (PID=3247) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:01.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:01.740+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:01.740+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:01.755+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:01.752+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 84, in <module>
    upload_file_reviews = GCSToGCSOperator(
                          ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_payments_to_capstone' has already been added to the DAG
[2024-05-04T11:24:01.756+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:01.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.052 seconds
[2024-05-04T11:24:09.535+0000] {processor.py:161} INFO - Started process (PID=3362) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:09.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:09.537+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:09.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:09.557+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:09.583+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:09.583+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:24:09.620+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:09.620+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:24:09.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.143 seconds
[2024-05-04T11:24:13.257+0000] {processor.py:161} INFO - Started process (PID=3417) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:13.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:13.259+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:13.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:13.280+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:13.302+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:13.300+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:24:13.339+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:13.338+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:24:13.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.112 seconds
[2024-05-04T11:24:20.218+0000] {processor.py:161} INFO - Started process (PID=3482) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:20.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:20.221+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:20.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:20.235+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:20.233+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 93, in <module>
    upload_file_orders = GCSToGCSOperator(
                         ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:24:20.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:20.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.052 seconds
[2024-05-04T11:24:22.610+0000] {processor.py:161} INFO - Started process (PID=3522) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:22.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:22.612+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:22.611+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:22.633+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:22.630+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 93, in <module>
    upload_file_orders = GCSToGCSOperator(
                         ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_reviews_to_capstone' has already been added to the DAG
[2024-05-04T11:24:22.634+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:22.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.062 seconds
[2024-05-04T11:24:28.653+0000] {processor.py:161} INFO - Started process (PID=3534) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:28.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:28.654+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:28.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:28.684+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:29.140+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:29.140+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:24:29.164+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:29.164+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:24:29.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.621 seconds
[2024-05-04T11:24:31.375+0000] {processor.py:161} INFO - Started process (PID=3539) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:31.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:31.376+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:31.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:31.390+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:31.401+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:31.401+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:24:31.419+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:31.419+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:24:31.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.069 seconds
[2024-05-04T11:24:33.929+0000] {processor.py:161} INFO - Started process (PID=3564) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:33.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:33.940+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:33.939+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:33.949+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:33.948+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 102
    upload_file_products = GCSToGCSOperator(
                                           ^
SyntaxError: '(' was never closed
[2024-05-04T11:24:33.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:33.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.073 seconds
[2024-05-04T11:24:36.187+0000] {processor.py:161} INFO - Started process (PID=3584) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:36.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:36.189+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:36.188+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:36.260+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:36.259+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 102, in <module>
    upload_file_products = GCSToGCSOperator(
                           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:24:36.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:36.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.166 seconds
[2024-05-04T11:24:45.333+0000] {processor.py:161} INFO - Started process (PID=3739) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:45.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:45.339+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:45.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:45.355+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:45.352+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 102, in <module>
    upload_file_products = GCSToGCSOperator(
                           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_orders_to_capstone' has already been added to the DAG
[2024-05-04T11:24:45.356+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:45.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.065 seconds
[2024-05-04T11:24:48.657+0000] {processor.py:161} INFO - Started process (PID=3769) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:24:48.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:24:48.659+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:48.659+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:24:48.673+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:24:48.671+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 102, in <module>
    upload_file_products = GCSToGCSOperator(
                           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:24:48.674+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:24:48.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.050 seconds
[2024-05-04T11:25:14.181+0000] {processor.py:161} INFO - Started process (PID=3986) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:14.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:14.186+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:14.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:14.206+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:14.203+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 102, in <module>
    upload_file_products = GCSToGCSOperator(
                           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_orders_to_capstone' has already been added to the DAG
[2024-05-04T11:25:14.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:14.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.059 seconds
[2024-05-04T11:25:22.324+0000] {processor.py:161} INFO - Started process (PID=4056) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:22.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:22.325+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:22.325+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:22.361+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:22.875+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:22.875+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:25:22.899+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:22.899+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:25:22.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.617 seconds
[2024-05-04T11:25:27.207+0000] {processor.py:161} INFO - Started process (PID=4091) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:27.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:27.208+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:27.208+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:27.221+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:27.220+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 110, in <module>
    upload_file_sellers = GCSToGCSOperator(
                          ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:25:27.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:27.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.049 seconds
[2024-05-04T11:25:31.236+0000] {processor.py:161} INFO - Started process (PID=4102) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:31.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:31.237+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:31.236+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:31.253+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:31.251+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 110, in <module>
    upload_file_sellers = GCSToGCSOperator(
                          ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_products_to_capstone' has already been added to the DAG
[2024-05-04T11:25:31.254+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:31.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.058 seconds
[2024-05-04T11:25:33.322+0000] {processor.py:161} INFO - Started process (PID=4107) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:33.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:33.323+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:33.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:33.335+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:33.333+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 110, in <module>
    upload_file_sellers = GCSToGCSOperator(
                          ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_products_to_capstone' has already been added to the DAG
[2024-05-04T11:25:33.335+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:33.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.038 seconds
[2024-05-04T11:25:40.191+0000] {processor.py:161} INFO - Started process (PID=4195) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:40.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:40.193+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:40.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:40.219+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:40.237+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:40.236+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:25:40.262+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:40.262+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:25:40.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.110 seconds
[2024-05-04T11:25:42.206+0000] {processor.py:161} INFO - Started process (PID=4240) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:42.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:42.209+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:42.208+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:42.261+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:42.315+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:42.315+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:25:42.357+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:42.356+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:25:42.402+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.205 seconds
[2024-05-04T11:25:47.442+0000] {processor.py:161} INFO - Started process (PID=4317) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:47.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:47.446+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:47.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:47.462+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:47.460+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 119, in <module>
    upload_file_name = GCSToGCSOperator(
                       ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 467, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'source_bucket'
[2024-05-04T11:25:47.463+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:47.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.053 seconds
[2024-05-04T11:25:53.964+0000] {processor.py:161} INFO - Started process (PID=4377) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:53.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:53.965+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:53.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:53.976+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:53.975+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 127
    )
    ^
SyntaxError: unmatched ')'
[2024-05-04T11:25:53.976+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:54.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.077 seconds
[2024-05-04T11:25:56.112+0000] {processor.py:161} INFO - Started process (PID=4387) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:25:56.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:25:56.113+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:56.113+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:25:56.124+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:25:56.122+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 119, in <module>
    upload_file_name = GCSToGCSOperator(
                       ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/gcs_to_gcs.py", line 200, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 899, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 232, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'upload_file_sellers_to_capstone' has already been added to the DAG
[2024-05-04T11:25:56.124+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:25:56.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.038 seconds
[2024-05-04T11:26:02.198+0000] {processor.py:161} INFO - Started process (PID=4397) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:26:02.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:26:02.210+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:02.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:26:02.233+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:26:02.555+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:02.555+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:26:02.581+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:02.581+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:26:02.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.424 seconds
[2024-05-04T11:26:32.914+0000] {processor.py:161} INFO - Started process (PID=4663) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:26:32.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:26:32.916+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:32.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:26:32.928+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:26:32.951+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:32.951+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:26:32.970+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:32.970+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:26:32.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-05-04T11:26:36.346+0000] {processor.py:161} INFO - Started process (PID=4683) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:26:36.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:26:36.348+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:36.348+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:26:36.368+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:26:36.513+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:36.513+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:26:36.529+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:36.529+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:26:36.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.212 seconds
[2024-05-04T11:26:51.439+0000] {processor.py:161} INFO - Started process (PID=4883) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:26:51.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:26:51.441+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:51.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:26:51.467+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:26:51.481+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:51.481+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:26:51.511+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:51.511+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:26:51.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.105 seconds
[2024-05-04T11:26:53.680+0000] {processor.py:161} INFO - Started process (PID=4903) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:26:53.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:26:53.681+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:53.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:26:53.698+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:26:53.696+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> get_files >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
             ^^^^^^^^^
NameError: name 'get_files' is not defined. Did you mean: '_get_files'?
[2024-05-04T11:26:53.700+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:26:53.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.057 seconds
[2024-05-04T11:27:05.153+0000] {processor.py:161} INFO - Started process (PID=4945) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:27:05.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:27:05.154+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:05.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:27:05.172+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:05.171+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2024-05-04T11:27:05.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:27:05.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.047 seconds
[2024-05-04T11:27:21.708+0000] {processor.py:161} INFO - Started process (PID=5160) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:27:21.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:27:21.719+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:21.717+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:27:21.787+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:21.782+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:27:21.802+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:27:21.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.155 seconds
[2024-05-04T11:27:32.512+0000] {processor.py:161} INFO - Started process (PID=5216) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:27:32.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:27:32.514+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:32.514+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:27:32.526+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:32.524+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:27:32.528+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:27:32.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.045 seconds
[2024-05-04T11:27:53.291+0000] {processor.py:161} INFO - Started process (PID=5441) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:27:53.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:27:53.295+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:53.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:27:53.324+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:27:53.313+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:27:53.327+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:27:53.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.083 seconds
[2024-05-04T11:28:22.777+0000] {processor.py:161} INFO - Started process (PID=5705) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:28:22.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:28:22.783+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:22.782+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:28:22.799+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:22.797+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:28:22.803+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:28:22.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.055 seconds
[2024-05-04T11:28:36.158+0000] {processor.py:161} INFO - Started process (PID=5752) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:28:36.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:28:36.160+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:36.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:28:36.173+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:36.171+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:28:36.174+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:28:36.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.042 seconds
[2024-05-04T11:28:40.735+0000] {processor.py:161} INFO - Started process (PID=5792) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:28:40.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:28:40.737+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:40.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:28:40.756+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:40.753+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:28:40.759+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:28:40.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.055 seconds
[2024-05-04T11:28:47.545+0000] {processor.py:161} INFO - Started process (PID=5897) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:28:47.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:28:47.546+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:47.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:28:47.565+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:47.562+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:28:47.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:28:47.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.056 seconds
[2024-05-04T11:28:50.465+0000] {processor.py:161} INFO - Started process (PID=5962) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:28:50.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:28:50.468+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:50.468+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:28:50.487+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:50.484+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:28:50.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:28:50.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.058 seconds
[2024-05-04T11:28:54.109+0000] {processor.py:161} INFO - Started process (PID=5992) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:28:54.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:28:54.111+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:54.111+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:28:54.131+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:28:54.127+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:28:54.145+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:28:54.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.070 seconds
[2024-05-04T11:29:24.476+0000] {processor.py:161} INFO - Started process (PID=6259) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:29:24.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:29:24.482+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:29:24.482+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:29:24.507+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:29:24.503+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:29:24.510+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:29:24.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.094 seconds
[2024-05-04T11:29:29.820+0000] {processor.py:161} INFO - Started process (PID=6305) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:29:29.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:29:29.821+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:29:29.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:29:29.833+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:29:29.831+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:29:29.835+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:29:29.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.042 seconds
[2024-05-04T11:30:00.109+0000] {processor.py:161} INFO - Started process (PID=6569) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:00.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:00.117+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:00.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:00.235+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:00.227+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined
[2024-05-04T11:30:00.242+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:00.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.293 seconds
[2024-05-04T11:30:15.469+0000] {processor.py:161} INFO - Started process (PID=6631) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:15.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:15.470+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:15.470+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:15.487+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:15.485+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers_to_capstone' is not defined. Did you mean: 'upload_file_customers_to'?
[2024-05-04T11:30:15.490+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:15.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.057 seconds
[2024-05-04T11:30:17.112+0000] {processor.py:161} INFO - Started process (PID=6679) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:17.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:17.113+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:17.113+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:17.141+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:17.138+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_geolocation_to_capstone' is not defined. Did you mean: 'upload_file_customers_to_capstone'?
[2024-05-04T11:30:17.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:17.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.064 seconds
[2024-05-04T11:30:20.847+0000] {processor.py:161} INFO - Started process (PID=6731) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:20.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:20.851+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:20.850+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:20.876+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:20.873+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_items_to_capstone' is not defined. Did you mean: 'upload_file_customers_to_capstone'?
[2024-05-04T11:30:20.879+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:20.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.110 seconds
[2024-05-04T11:30:23.549+0000] {processor.py:161} INFO - Started process (PID=6801) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:23.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:23.550+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:23.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:23.563+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:23.561+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_items_to_capstone' is not defined. Did you mean: 'upload_file_customers_to_capstone'?
[2024-05-04T11:30:23.564+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:23.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.040 seconds
[2024-05-04T11:30:24.765+0000] {processor.py:161} INFO - Started process (PID=6816) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:24.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:24.766+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:24.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:24.779+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:24.777+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_name_to_capstone' is not defined. Did you mean: 'upload_file_items_to_capstone'?
[2024-05-04T11:30:24.780+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:24.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.041 seconds
[2024-05-04T11:30:28.123+0000] {processor.py:161} INFO - Started process (PID=6851) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:28.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:28.125+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:28.124+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:28.152+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:28.150+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_name_to_capstone' is not defined. Did you mean: 'upload_file_items_to_capstone'?
[2024-05-04T11:30:28.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:28.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.086 seconds
[2024-05-04T11:30:31.135+0000] {processor.py:161} INFO - Started process (PID=6862) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:31.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:31.138+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:31.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:31.159+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:31.156+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_name_to_capstone' is not defined. Did you mean: 'upload_file_items_to_capstone'?
[2024-05-04T11:30:31.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:31.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.062 seconds
[2024-05-04T11:30:34.287+0000] {processor.py:161} INFO - Started process (PID=6872) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:34.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:34.295+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:34.294+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:34.335+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:34.330+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_name_to_capstone' is not defined. Did you mean: 'upload_file_items_to_capstone'?
[2024-05-04T11:30:34.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:34.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.114 seconds
[2024-05-04T11:30:37.354+0000] {processor.py:161} INFO - Started process (PID=6877) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:37.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:37.355+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:37.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:37.369+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:37.366+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_name_to_capstone' is not defined. Did you mean: 'upload_file_items_to_capstone'?
[2024-05-04T11:30:37.371+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:37.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.041 seconds
[2024-05-04T11:30:40.553+0000] {processor.py:161} INFO - Started process (PID=6892) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:40.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:40.566+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:40.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:40.618+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:40.597+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_name_to_capstone' is not defined. Did you mean: 'upload_file_items_to_capstone'?
[2024-05-04T11:30:40.623+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:40.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.145 seconds
[2024-05-04T11:30:43.062+0000] {processor.py:161} INFO - Started process (PID=6922) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:30:43.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:30:43.064+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:43.064+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:30:43.089+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:30:43.079+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                                                                                                                                                                                                                             ^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers' is not defined
[2024-05-04T11:30:43.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:30:43.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.068 seconds
[2024-05-04T11:31:13.317+0000] {processor.py:161} INFO - Started process (PID=7186) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:31:13.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:31:13.318+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:31:13.318+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:31:13.393+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:31:13.359+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                                                                                                                                                                                                                             ^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers' is not defined
[2024-05-04T11:31:13.433+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:31:13.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.173 seconds
[2024-05-04T11:31:43.951+0000] {processor.py:161} INFO - Started process (PID=7439) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:31:43.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:31:43.953+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:31:43.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:31:43.979+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:31:43.968+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236, in <module>
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >> [upload_file_customers, upload_file_geolocation, upload_file_items, upload_file_name ,upload_file_orders, upload_file_payments, upload_file_products, upload_file_reviews, upload_file_sellers] >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                                                                                                                                                                                                                             ^^^^^^^^^^^^^^^^^^^^^
NameError: name 'upload_file_customers' is not defined
[2024-05-04T11:31:43.989+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:31:44.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.081 seconds
[2024-05-04T11:31:59.375+0000] {processor.py:161} INFO - Started process (PID=7674) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:31:59.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:31:59.376+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:31:59.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:31:59.381+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:31:59.380+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 236
    start >> [upload_file_customers_to_capstone, upload_file_geolocation_to_capstone, upload_file_items_to_capstone, upload_file_name_to_capstone ,upload_file_orders_to_capstone, upload_file_payments_to_capstone, upload_file_products_to_capstone, upload_file_reviews_to_capstone, upload_file_sellers_to_capstone] >>  >> create_order_dataset >> [gcs_to_bq_customers, gcs_to_bq_geolocation, gcs_to_bq_items, gcs_to_bq_orders, gcs_to_bq_payments, gcs_to_bq_products, gcs_to_bq_reviews, gcs_to_bq_sellers, gcs_to_bq_translation]
                                                                                                                                                                                                                                                                                                                             ^^
SyntaxError: invalid syntax
[2024-05-04T11:31:59.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:31:59.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.032 seconds
[2024-05-04T11:32:02.400+0000] {processor.py:161} INFO - Started process (PID=7685) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:32:02.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:32:02.402+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:32:02.401+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:32:02.418+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:32:02.551+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:32:02.551+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:32:02.566+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:32:02.566+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:32:02.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.198 seconds
[2024-05-04T11:32:33.385+0000] {processor.py:161} INFO - Started process (PID=7948) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:32:33.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:32:33.393+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:32:33.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:32:33.531+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:32:33.758+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:32:33.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:32:33.947+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:32:33.947+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:32:34.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.703 seconds
[2024-05-04T11:33:04.410+0000] {processor.py:161} INFO - Started process (PID=8244) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:33:04.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:33:04.412+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:33:04.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:33:04.441+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:33:04.478+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:33:04.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:33:04.505+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:33:04.505+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:33:04.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.124 seconds
[2024-05-04T11:33:34.569+0000] {processor.py:161} INFO - Started process (PID=8510) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:33:34.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:33:34.571+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:33:34.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:33:34.589+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:33:34.623+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:33:34.623+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:33:34.658+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:33:34.657+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:33:34.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.118 seconds
[2024-05-04T11:34:04.799+0000] {processor.py:161} INFO - Started process (PID=8771) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:34:04.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:34:04.800+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:34:04.799+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:34:04.819+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:34:04.854+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:34:04.853+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:34:04.877+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:34:04.877+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:34:04.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.113 seconds
[2024-05-04T11:34:35.362+0000] {processor.py:161} INFO - Started process (PID=9022) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:34:35.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:34:35.364+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:34:35.363+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:34:35.381+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:34:35.418+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:34:35.418+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:34:35.442+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:34:35.442+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:34:35.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.111 seconds
[2024-05-04T11:35:07.385+0000] {processor.py:161} INFO - Started process (PID=9313) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:35:07.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:35:07.407+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:35:07.406+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:35:07.620+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:35:08.059+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:35:08.056+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:35:08.116+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:35:08.116+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:35:08.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.895 seconds
[2024-05-04T11:35:38.687+0000] {processor.py:161} INFO - Started process (PID=9607) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:35:38.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:35:38.695+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:35:38.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:35:38.729+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:35:38.765+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:35:38.765+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:35:38.822+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:35:38.822+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:35:38.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.187 seconds
[2024-05-04T11:36:09.553+0000] {processor.py:161} INFO - Started process (PID=9874) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:36:09.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:36:09.555+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:36:09.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:36:09.592+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:36:09.722+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:36:09.722+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:36:09.773+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:36:09.773+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:36:09.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.272 seconds
[2024-05-04T11:36:40.366+0000] {processor.py:161} INFO - Started process (PID=10140) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:36:40.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:36:40.368+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:36:40.367+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:36:40.385+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:36:40.425+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:36:40.425+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:36:40.472+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:36:40.471+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:36:40.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.142 seconds
[2024-05-04T11:37:11.133+0000] {processor.py:161} INFO - Started process (PID=10406) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:37:11.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:37:11.136+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:11.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:37:11.154+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:37:11.192+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:11.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:37:11.219+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:11.219+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:37:11.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.118 seconds
[2024-05-04T11:37:23.771+0000] {processor.py:161} INFO - Started process (PID=10501) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:37:23.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:37:23.781+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:23.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:37:23.805+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:23.803+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/etl.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl.py", line 35, in <module>
    start_date=timezone.datetime(2024,5,),
                                        ^
NameError: name '' is not defined
[2024-05-04T11:37:23.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:37:23.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.142 seconds
[2024-05-04T11:37:24.612+0000] {processor.py:161} INFO - Started process (PID=10519) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:37:24.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:37:24.630+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:24.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:37:24.700+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:37:25.219+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:25.219+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:37:25.268+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:25.267+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:37:25.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.763 seconds
[2024-05-04T11:37:56.075+0000] {processor.py:161} INFO - Started process (PID=10787) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:37:56.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:37:56.077+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:56.077+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:37:56.095+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:37:56.129+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:56.129+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:37:56.160+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:37:56.160+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:37:56.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.115 seconds
[2024-05-04T11:38:26.532+0000] {processor.py:161} INFO - Started process (PID=11098) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:38:26.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:38:26.546+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:38:26.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:38:26.654+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:38:26.842+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:38:26.842+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:38:27.011+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:38:27.010+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:38:27.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.594 seconds
[2024-05-04T11:38:57.562+0000] {processor.py:161} INFO - Started process (PID=11370) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:38:57.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:38:57.564+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:38:57.564+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:38:57.585+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:38:57.624+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:38:57.623+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:38:57.650+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:38:57.650+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:38:57.676+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.121 seconds
[2024-05-04T11:39:27.743+0000] {processor.py:161} INFO - Started process (PID=11636) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:39:27.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:39:27.744+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:27.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:39:27.768+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:39:27.808+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:27.808+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:39:27.833+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:27.833+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:39:27.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.122 seconds
[2024-05-04T11:39:57.941+0000] {processor.py:161} INFO - Started process (PID=11898) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:39:57.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:39:57.942+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:57.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:39:57.961+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:39:58.000+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:57.999+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:39:58.027+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:58.027+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:39:58.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.119 seconds
[2024-05-04T11:39:59.240+0000] {processor.py:161} INFO - Started process (PID=11918) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:39:59.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:39:59.242+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:59.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:39:59.287+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:39:59.456+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:59.456+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:39:59.477+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:39:59.477+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:39:59.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.280 seconds
[2024-05-04T11:40:10.976+0000] {processor.py:161} INFO - Started process (PID=12029) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:40:10.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:40:10.977+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:10.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:40:10.992+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:40:11.006+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:11.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:40:11.026+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:11.026+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:40:11.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.076 seconds
[2024-05-04T11:40:12.251+0000] {processor.py:161} INFO - Started process (PID=12044) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:40:12.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:40:12.252+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:12.252+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:40:12.275+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:40:12.290+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:12.290+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:40:12.318+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:12.318+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:40:12.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.100 seconds
[2024-05-04T11:40:21.894+0000] {processor.py:161} INFO - Started process (PID=12154) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:40:21.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:40:21.895+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:21.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:40:21.909+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:40:21.918+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:21.918+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:40:21.937+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:21.937+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:40:21.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.068 seconds
[2024-05-04T11:40:26.175+0000] {processor.py:161} INFO - Started process (PID=12179) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:40:26.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:40:26.176+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:26.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:40:26.204+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:40:26.230+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:26.230+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:40:26.309+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:26.309+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:40:26.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.219 seconds
[2024-05-04T11:40:41.571+0000] {processor.py:161} INFO - Started process (PID=12311) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:40:41.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:40:41.572+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:41.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:40:41.595+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:40:41.741+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:41.740+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:40:41.791+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:40:41.791+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:40:41.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.267 seconds
[2024-05-04T11:41:13.107+0000] {processor.py:161} INFO - Started process (PID=12628) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:41:13.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:41:13.146+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:13.146+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:41:13.383+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:41:13.707+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:13.707+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:41:13.967+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:13.967+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:41:14.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 1.258 seconds
[2024-05-04T11:41:44.607+0000] {processor.py:161} INFO - Started process (PID=12905) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:41:44.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:41:44.608+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:44.608+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:41:44.621+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:41:44.644+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:44.644+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:41:44.661+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:44.661+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:41:44.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.078 seconds
[2024-05-04T11:41:46.882+0000] {processor.py:161} INFO - Started process (PID=12930) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:41:46.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:41:46.883+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:46.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:41:46.906+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:41:47.191+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:47.191+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:41:47.236+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:41:47.236+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:41:47.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.388 seconds
[2024-05-04T11:42:18.096+0000] {processor.py:161} INFO - Started process (PID=13217) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:42:18.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:42:18.126+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:42:18.126+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:42:18.272+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:42:18.518+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:42:18.518+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:42:18.684+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:42:18.684+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:42:18.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.778 seconds
[2024-05-04T11:42:49.391+0000] {processor.py:161} INFO - Started process (PID=13523) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:42:49.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:42:49.393+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:42:49.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:42:49.432+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:42:49.478+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:42:49.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:42:49.509+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:42:49.509+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:42:49.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.162 seconds
[2024-05-04T11:43:27.778+0000] {processor.py:161} INFO - Started process (PID=13803) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:43:27.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:43:27.826+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:43:27.825+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:43:29.735+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:43:29.789+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:43:29.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:43:29.822+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:43:29.822+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:43:29.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 2.110 seconds
[2024-05-04T11:43:59.936+0000] {processor.py:161} INFO - Started process (PID=14084) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:43:59.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:43:59.938+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:43:59.937+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:43:59.950+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:43:59.972+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:43:59.972+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:43:59.993+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:43:59.993+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:44:00.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.099 seconds
[2024-05-04T11:44:30.948+0000] {processor.py:161} INFO - Started process (PID=14350) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:44:30.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:44:30.949+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:44:30.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:44:30.962+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:44:30.984+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:44:30.984+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:44:31.003+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:44:31.003+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:44:31.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.080 seconds
[2024-05-04T11:45:01.427+0000] {processor.py:161} INFO - Started process (PID=14616) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:45:01.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:45:01.428+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:45:01.428+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:45:01.448+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:45:01.494+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:45:01.493+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:45:01.542+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:45:01.542+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:45:01.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.150 seconds
[2024-05-04T11:45:32.218+0000] {processor.py:161} INFO - Started process (PID=14882) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:45:32.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:45:32.220+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:45:32.219+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:45:32.249+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:45:32.292+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:45:32.292+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:45:32.320+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:45:32.320+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:45:32.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.160 seconds
[2024-05-04T11:46:03.264+0000] {processor.py:161} INFO - Started process (PID=15148) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:46:03.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:46:03.266+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:46:03.266+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:46:03.286+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:46:03.325+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:46:03.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:46:03.351+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:46:03.351+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:46:03.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.118 seconds
[2024-05-04T11:46:34.280+0000] {processor.py:161} INFO - Started process (PID=15415) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:46:34.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:46:34.282+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:46:34.281+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:46:34.301+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:46:34.346+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:46:34.346+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:46:34.380+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:46:34.380+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:46:34.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.133 seconds
[2024-05-04T11:47:04.930+0000] {processor.py:161} INFO - Started process (PID=15680) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:47:04.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:47:04.932+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:47:04.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:47:04.951+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:47:04.993+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:47:04.993+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:47:05.021+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:47:05.021+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:47:05.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.139 seconds
[2024-05-04T11:47:35.332+0000] {processor.py:161} INFO - Started process (PID=15946) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:47:35.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:47:35.334+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:47:35.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:47:35.353+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:47:35.386+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:47:35.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:47:35.424+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:47:35.423+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:47:35.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.125 seconds
[2024-05-04T11:48:05.639+0000] {processor.py:161} INFO - Started process (PID=16211) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:48:05.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:48:05.641+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:48:05.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:48:05.660+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:48:05.694+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:48:05.694+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:48:05.736+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:48:05.736+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:48:05.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.128 seconds
[2024-05-04T11:48:35.816+0000] {processor.py:161} INFO - Started process (PID=16477) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:48:35.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:48:35.818+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:48:35.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:48:35.836+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:48:35.873+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:48:35.872+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:48:35.899+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:48:35.898+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:48:35.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.125 seconds
[2024-05-04T11:49:06.358+0000] {processor.py:161} INFO - Started process (PID=16743) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:49:06.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:49:06.360+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:49:06.359+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:49:06.378+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:49:06.420+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:49:06.420+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:49:06.456+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:49:06.455+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:49:06.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.130 seconds
[2024-05-04T11:49:37.056+0000] {processor.py:161} INFO - Started process (PID=17009) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:49:37.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:49:37.058+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:49:37.058+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:49:37.102+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:49:37.184+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:49:37.184+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:49:37.217+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:49:37.216+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:49:37.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.203 seconds
[2024-05-04T11:50:07.667+0000] {processor.py:161} INFO - Started process (PID=17275) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:50:07.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:50:07.668+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:50:07.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:50:07.686+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:50:07.739+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:50:07.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:50:07.780+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:50:07.780+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:50:07.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.166 seconds
[2024-05-04T11:50:38.306+0000] {processor.py:161} INFO - Started process (PID=17547) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:50:38.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:50:38.307+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:50:38.307+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:50:38.327+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:50:38.369+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:50:38.369+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:50:38.393+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:50:38.393+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:50:38.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.116 seconds
[2024-05-04T11:51:08.815+0000] {processor.py:161} INFO - Started process (PID=17813) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:51:08.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:51:08.827+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:51:08.827+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:51:08.857+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:51:08.944+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:51:08.944+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:51:08.983+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:51:08.982+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:51:09.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.219 seconds
[2024-05-04T11:51:39.197+0000] {processor.py:161} INFO - Started process (PID=18080) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:51:39.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:51:39.198+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:51:39.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:51:39.218+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:51:39.255+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:51:39.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:51:39.282+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:51:39.281+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:51:39.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.113 seconds
[2024-05-04T11:52:09.743+0000] {processor.py:161} INFO - Started process (PID=18347) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:52:09.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:52:09.745+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:52:09.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:52:09.764+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:52:09.798+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:52:09.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:52:09.823+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:52:09.822+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:52:09.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.108 seconds
[2024-05-04T11:52:40.095+0000] {processor.py:161} INFO - Started process (PID=18613) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:52:40.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:52:40.096+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:52:40.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:52:40.115+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:52:40.155+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:52:40.154+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:52:40.182+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:52:40.181+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:52:40.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.119 seconds
[2024-05-04T11:53:10.392+0000] {processor.py:161} INFO - Started process (PID=18880) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:53:10.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:53:10.393+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:53:10.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:53:10.413+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:53:10.447+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:53:10.446+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:53:10.476+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:53:10.476+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:53:10.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.145 seconds
[2024-05-04T11:53:41.027+0000] {processor.py:161} INFO - Started process (PID=19147) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:53:41.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:53:41.029+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:53:41.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:53:41.048+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:53:41.095+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:53:41.094+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:53:41.147+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:53:41.144+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:53:41.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.182 seconds
[2024-05-04T11:54:11.311+0000] {processor.py:161} INFO - Started process (PID=19414) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:54:11.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:54:11.312+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:54:11.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:54:11.331+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:54:11.369+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:54:11.369+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:54:11.392+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:54:11.392+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:54:11.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.109 seconds
[2024-05-04T11:54:41.480+0000] {processor.py:161} INFO - Started process (PID=19680) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:54:41.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:54:41.482+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:54:41.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:54:41.500+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:54:41.553+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:54:41.552+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:54:41.579+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:54:41.579+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:54:41.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.133 seconds
[2024-05-04T11:55:11.708+0000] {processor.py:161} INFO - Started process (PID=19946) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:55:11.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:55:11.710+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:55:11.710+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:55:11.729+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:55:11.763+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:55:11.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:55:11.790+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:55:11.790+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:55:11.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.116 seconds
[2024-05-04T11:55:41.951+0000] {processor.py:161} INFO - Started process (PID=20213) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:55:41.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:55:41.952+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:55:41.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:55:41.971+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:55:42.004+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:55:42.004+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:55:42.032+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:55:42.032+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:55:42.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.110 seconds
[2024-05-04T11:56:12.403+0000] {processor.py:161} INFO - Started process (PID=20479) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:56:12.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:56:12.405+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:56:12.405+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:56:12.424+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:56:12.462+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:56:12.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:56:12.489+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:56:12.489+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:56:12.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.117 seconds
[2024-05-04T11:56:43.327+0000] {processor.py:161} INFO - Started process (PID=20746) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:56:43.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:56:43.329+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:56:43.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:56:43.347+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:56:43.386+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:56:43.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:56:43.445+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:56:43.444+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:56:43.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.146 seconds
[2024-05-04T11:57:13.518+0000] {processor.py:161} INFO - Started process (PID=21013) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:57:13.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:57:13.520+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:57:13.520+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:57:13.540+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:57:13.575+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:57:13.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:57:13.603+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:57:13.603+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:57:13.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.117 seconds
[2024-05-04T11:57:44.284+0000] {processor.py:161} INFO - Started process (PID=21280) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:57:44.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:57:44.286+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:57:44.286+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:57:44.305+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:57:44.342+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:57:44.342+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:57:44.369+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:57:44.368+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:57:44.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.127 seconds
[2024-05-04T11:58:14.684+0000] {processor.py:161} INFO - Started process (PID=21546) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:58:14.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:58:14.687+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:58:14.686+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:58:14.706+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:58:14.742+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:58:14.742+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:58:14.779+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:58:14.779+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:58:14.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.140 seconds
[2024-05-04T11:58:45.495+0000] {processor.py:161} INFO - Started process (PID=21812) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:58:45.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:58:45.497+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:58:45.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:58:45.515+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:58:45.552+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:58:45.552+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:58:45.580+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:58:45.579+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:58:45.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.114 seconds
[2024-05-04T11:59:15.914+0000] {processor.py:161} INFO - Started process (PID=22079) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:59:15.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:59:15.916+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:59:15.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:59:15.935+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:59:15.973+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:59:15.972+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:59:16.000+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:59:15.999+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:59:16.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.115 seconds
[2024-05-04T11:59:46.682+0000] {processor.py:161} INFO - Started process (PID=22345) to work on /opt/airflow/dags/etl.py
[2024-05-04T11:59:46.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T11:59:46.684+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:59:46.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T11:59:46.704+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T11:59:46.738+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:59:46.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T11:59:46.764+0000] {logging_mixin.py:188} INFO - [2024-05-04T11:59:46.764+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T11:59:46.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.110 seconds
[2024-05-04T12:00:17.700+0000] {processor.py:161} INFO - Started process (PID=22612) to work on /opt/airflow/dags/etl.py
[2024-05-04T12:00:17.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T12:00:17.702+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:00:17.701+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T12:00:17.721+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T12:00:17.776+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:00:17.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T12:00:17.847+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:00:17.846+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T12:00:17.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.218 seconds
[2024-05-04T12:00:48.048+0000] {processor.py:161} INFO - Started process (PID=22883) to work on /opt/airflow/dags/etl.py
[2024-05-04T12:00:48.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T12:00:48.049+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:00:48.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T12:00:48.061+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T12:00:48.083+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:00:48.083+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T12:00:48.107+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:00:48.107+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T12:00:48.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.083 seconds
[2024-05-04T12:01:18.322+0000] {processor.py:161} INFO - Started process (PID=23144) to work on /opt/airflow/dags/etl.py
[2024-05-04T12:01:18.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T12:01:18.325+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:01:18.325+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T12:01:18.344+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T12:01:18.378+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:01:18.378+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T12:01:18.405+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:01:18.405+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T12:01:18.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.112 seconds
[2024-05-04T12:01:48.712+0000] {processor.py:161} INFO - Started process (PID=23410) to work on /opt/airflow/dags/etl.py
[2024-05-04T12:01:48.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T12:01:48.714+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:01:48.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T12:01:48.735+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T12:01:48.772+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:01:48.771+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T12:01:48.797+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:01:48.796+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T12:01:48.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.112 seconds
[2024-05-04T12:02:18.998+0000] {processor.py:161} INFO - Started process (PID=23677) to work on /opt/airflow/dags/etl.py
[2024-05-04T12:02:18.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl.py for tasks to queue
[2024-05-04T12:02:19.000+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:02:19.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/etl.py
[2024-05-04T12:02:19.020+0000] {processor.py:840} INFO - DAG(s) 'etl' retrieved from /opt/airflow/dags/etl.py
[2024-05-04T12:02:19.052+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:02:19.052+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-05-04T12:02:19.077+0000] {logging_mixin.py:188} INFO - [2024-05-04T12:02:19.076+0000] {dag.py:3954} INFO - Setting next_dagrun for etl to 2024-05-04 00:00:00+00:00, run_after=2024-05-05 00:00:00+00:00
[2024-05-04T12:02:19.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl.py took 0.107 seconds
